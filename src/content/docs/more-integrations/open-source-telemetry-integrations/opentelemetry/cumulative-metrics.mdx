---
title: Cumulative Metrics with New Relic
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
metaDescription: Support for cumulative metrics at New Relic
---

import moreintegrationsOtlpFacetQuery from 'images/more-integrations_screenshot-crop_otlp-facet-query.png'

When collecting metric data from an application, it's important to consider _how_ that data was measured when deciding how to use and interpret it at query time. The **type** of a metric is one important factor, with [certain aggregation functions working with some types and not others]([url](https://docs.newrelic.com/docs/data-apis/understand-data/metric-data/query-metric-data-type/#view-and-query)), but another is the **temporality** of the metric. The two **temporalities** are **delta** and **cumulative**, the former of which indicates that measurements are reset between reporting intervals whereas the latter does not. Prometheus is a common example of a [cumulative metrics](https://prometheus.io/docs/concepts/metric_types/) collector, and [OpenTelemetry](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#temporality) also defines ways to collect cumulative metrics. 

New Relic supports sending Prometheus and OpenTelemetry cumulative data and will perform delta conversion at ingest to make interacting with that data via [NRQL](https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/) easier and more in line with other metrics in the New Relic platform. 

## Prometheus Remote Write Support

For more information, refer to our [Prometheus Remote Write](https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/) documentation.

## OpenTelemetry Support

[OpenTelemetry defines support](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#metric-points) for collecting and sending cumulative Sums and cumulative Histograms. New Relic will statefully reorder, buffer data, and emit deltas between sequential metric measurements in event time. If data for a [timeseries](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#timeseries-model) suddenly decreases in value, we treat this as a reset and will emit that new measurement as its own delta value (i.e. as if it were preceded by a 0 measurement). [OpenTelemetry also defines](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#resets-and-gaps) situations where a decrease in value is unexpected, and we do our best to detect these cases and notify you via [New Relic Integration Errors](https://docs.newrelic.com/docs/data-apis/manage-data/nrintegrationerror/) (see troubleshooting below).

### Cumulative Sums

To query your cumulative Sum as a delta, you query it like it were any other delta metric sent to New Relic. For example, if you wanted the change of your metric overtime you can query that like so:

```sql
FROM Metric SELECT rate(sum(my.cumulative.sum), 1 minute) TIMESERIES
```

Even though the data was recorded by your application and sent as a sequence of monotonically increasing values, calling sum() on it will treat it as though it were a sequence of delta values; no need to compute any derivative()!

When converting a sum to a delta, New Relic will also emit the cumulative value alongside the delta to maintain the ability for you to query the latest cumulative value. To chart the cumulative value, run a query like this:

```sql
FROM Metric SELECT latest(my.cumulative.sum[cumulative]) TIMESERIES
```

Note that data points are plotted at their associated `timestamps` which are the start of an interval. However, cumulative values are associated with the `endTimestamp` of the data point, so you may need to consider the width of a data point when interpreting cumulative queries.


### Cumulative Histograms

OpenTelemetry defines support for both [Explicit Bound Histograms](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#histogram) as well as [Exponential Histograms](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#exponentialhistogram), and New Relic can accept either. Querying cumulative histograms is the same as querying any other histogram, as we convert it to a delta for you:

```sql
FROM Metric SELECT histogram(my.cumulative.histogram)
```

Percentiles work as well:

```sql
FROM Metric SELECT percentile(my.cumulative.histogram, 95, 99) TIMESERIES
```

Unlike cumulative Sums, however, we do not store the original cumulative representation of the Histogram, so only the delta representation is queryable.

## Troubleshooting and Known Limitations

### Reordering Data

We understand that many things can cause data points to arrive at New Relic out of order. As such, we will buffer data points and reorder them if we detect an unexpected gap in the reporting timeseries. Buffering is bounded and eventually we will consider a data point "too late for resequencing". In this case, a delta is computed across the detected gap and processing of the timeseries continues.

### Stale Data

As delta conversion is a stateful operation, we must be cognizant of timeseries that may stop reporting and eventually drop its state. If a timeseries has not reported any new data points for **5 minutes**, we will flush the state we have, including computing deltas across any buffered gaps. This means that if a data point arrives at a later point in time, it will be treated as if it were the beginning of that timeseries, effectively losing the delta between the last data point before the flush and the first data point after the flush. This means that metric reporting intervals should be less than **5 minutes** to get the benefit of delta conversion.

### Translation Errors

Delta conversion involves the assumption that two data points sequential in event time will have monotonically increasing cumulative values. The only time this assumption is expected to break is when the process being monitored is restarted. If monotonicity is broken for any other reason we will still treat this as a reset, but will attempt to notify you by emitting a [New Relic Integration Error](https://docs.newrelic.com/docs/data-apis/manage-data/nrintegrationerror/) into your account. This is possible to do for OpenTelemetry data **but not Prometheus**, as OpenTelemetry includes more information that can be used to detect such situations. The most common cause for an unexpected break in monotonicity is when the client side application hits cardinality limits and drops data to relieve memory pressure. In certain cases, this acts as an unexpected reset and can result in an unexpected decrease in values sent to New Relic. It is recommended that you look for instances of this in your OTLP logs:

> **Instrument % has exceeded the maximum allowed accumulations (2000)**

OpenTelemetry provides a way to reduce cardinality client side using [**Views**](https://opentelemetry.io/docs/reference/specification/metrics/sdk/#view) and is the recommended path to fix these issues. Another option is to explore exporting your [OTLP metrics using Delta temporality](https://opentelemetry.io/docs/reference/specification/metrics/sdk_exporters/otlp/#additional-configuration) which can help save on memory.

### Cardinality Limits

During translation, we also loosely enforce metric cardinality limits that are based on your metric entitlements as a system protection. Rather than enforcing the limit [_per day_ as we do with rollups](https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes/#violation-unique-timeseries), this limit is enforced as the number of concurrent timeseries being tracked. Once there are too many concurrent [unique metric timeseries](https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/#what-why), we will drop new incoming timeseries until an old one ages out (see Stale Data).
